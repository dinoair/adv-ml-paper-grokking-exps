---
data:
  train: "dataset/language_variation_split/lang_var_train_vol_01.json"
  dev: "dataset/language_variation_split/lang_var_dev_vol_01.json"
  test: "dataset/language_variation_split/lang_var_test_vol_01.json"

# for training
hf_tokenizer: "DeepPavlov/rubert-base-cased-conversational"
hf_transformer: "DeepPavlov/rubert-base-cased-conversational"
enable_attention: True

epochs: 1000
learning_rate: 0.0001
num_warmup_steps: 10000
batch_size: 32
n_last_layers2train: 3

run_name: "3_layer_bert_decoder_attention_cp"

# for testing
save_model_path: "experiments"
inference_model_name: "3_layer_bert_decoder_attention_seq2seq.tar"

predictions_path: "predictions"
