---
data:
  train: "dataset/target_length_split/english_train_split_above_50_percentile.json"
  dev: "dataset/target_length_split/english_dev_split_below_50_percentile.json"
  test: "dataset/target_length_split/english_test_split_below_50_percentile.json"
  dataset_vocab: "dataset/dataset_vocab.json"

model:
  used_model: "vanilla"
  vanilla:
    tokenizer: "/home/etutubalina/somov-od/pretrained_models/bert_base_tokenizer"
    model: "/home/etutubalina/somov-od/pretrained_models/bert_base"
    enable_attention: True
    epochs_num: 1000
    bert_finetune_rate: 0.00006
    learning_rate: 0.0005
    bert_warmup_init_finetuning_learning_rate: 0.00003
    warm_up_init_learning_rate: 0.0005
    warmup_steps: 4000
    batch_size: 32
    n_last_layers2train: 12
  t5:
    tokenizer: "/home/etutubalina/somov-od/pretrained_models/t5_base_tokenizer"
    model: "/home/etutubalina/somov-od/pretrained_models/t5_base"
    epochs_num: 1000
    learning_rate: 0.001
    warmup_steps: 1000
    batch_size: 32

run_name: "en_tl_vanilla_run"

# for testing
save_model_path: "experiments"
inference_model_name: "en_one_batch_lstm_with_tf_vanilla_run/epoch_373_gm_0.93_em_0.72_vanilla.pt"