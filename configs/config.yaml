---
data:
  train: "dataset/lang_var_train_vol_01.json"
  dev: "dataset/lang_var_dev_vol_01.json"
  test: "dataset/lang_var_test_vol_01.json"

# for training
hf_tokenizer: "DeepPavlov/rubert-base-cased-conversational"
hf_transformer: "DeepPavlov/rubert-base-cased-conversational"

epochs: 1000
learning_rate: 0.0001
num_warmup_steps: 42
batch_size: 32
n_last_layers2train: 0

run_name: "pooler_bert_with_gru_attention_one_batch"

# for testing
save_model_path: "experiments"
inference_model_name: "last 3 layers+pooler+attention+decoder on base_seq2seq.tar"

predictions_path: "predictions"
