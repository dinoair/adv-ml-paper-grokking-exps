---
data:
  train: "dataset/language_variation_split/english_train_split.json"
  dev: "dataset/language_variation_split/english_dev_split.json"
  test: "dataset/language_variation_split/english_test_split.json"

model:
  used_model: "vanilla"
  vanilla:
    tokenizer: "cointegrated/rubert-tiny"
    model: "cointegrated/rubert-tiny"
    enable_attention: True
    epochs_num: 1000
    learning_rate: 0.0001
    warmup_steps: 10000
    batch_size: 32
    n_last_layers2train: 1
  t5:
    tokenizer: "t5-small"
    model: "t5-small"
    epochs_num: 1000
    learning_rate: 0.0001
    warmup_steps: 1000
    batch_size: 32

run_name: "t5_one_batch_test_run"

# for testing
save_model_path: "experiments"
inference_model_name: "3_layer_bert_decoder_attention_seq2seq.tar"

predictions_path: "predictions"
